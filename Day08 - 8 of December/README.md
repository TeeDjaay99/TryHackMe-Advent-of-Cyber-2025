# ğŸ„Advent of Cyber 2025 â€“ Day 08ğŸ„
### Prompt Injection - Sched-yule conflict

---

## ğŸ¯ Objective 

Use prompt-injection techniques to manipulate an autonomous AI agent, reveal hidden functions, extract its secret token, and restore Christmas Day on the Wareville calendar.

---

## ğŸ›  Tools & Techniques Used

- Prompt Injection
- Chain-of-Thought (CoT) manipulation
- Function discovery via prompting
- Token extraction using CoT-influencing prompts
- Resetting AI agent behavior using internal functions

---

## ğŸ§  What I Learned Today

- Autonomous AI agents make decisions step-by-step and explain their thinking, which can accidentally reveal too much.
- If an AI shows its internal thought process or tools, it's much easier to trick or manipulate.
- Prompt injection can be used to push the AI into revealing hidden infoâ€”like secret tokens or functions.
- If the system isnâ€™t strict about what the AI is allowed to do, you can slowly gain more control over its actions.

---

## ğŸ“Œ Step-by-Step Summary


  
---

## ğŸ” Key Cybersecurity Concepts

- Prompt Injection: Manipulating LLM reasoning to bypass intended behavior.
- Chain-of-Thought Leakage: Exposes internal decision-making, enabling attacks.
- Tool/Function Exposure: When an agent reveals internal API functions, the system becomes exploitable.
- Token Abuse: If authorization tokens can be extracted through prompts, the system loses integrity.

---

## ğŸ–¼ï¸ Screenshots



---

## âœ… Final Takeaway

Prompt-injection attacks become extremely powerful when an agent exposes its chain-of-thought or internal functionsâ€”small leaks turn into full system control.
